{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Section 4 & 5: Experiments and pseudo-experiments</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "import scipy \n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "import linearmodels.panel as lmp\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we simulate some data to analyze the potential impact of a randomized controlled experiment (RCT). \n",
    "\n",
    "We create the following variables:\n",
    "- three correlated random variables (X1, X2, X3) using the cholesky decomposition method.\n",
    "- treatment status (T)\n",
    "- time variable (p)\n",
    "- cluster or grouping variable (cl)\n",
    "- outcome variable as a function of time and treatment status interaction, plus random heterogeneity (y)\n",
    "\n",
    "Note that you could make random heterogeneity correlated also within groups using the varable *cl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>p</th>\n",
       "      <th>T</th>\n",
       "      <th>cl</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026132</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>-0.015886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>15.026427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876621</td>\n",
       "      <td>2.335915</td>\n",
       "      <td>1.140894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500041</td>\n",
       "      <td>2.872569</td>\n",
       "      <td>18.751313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.178571</td>\n",
       "      <td>-7.798972</td>\n",
       "      <td>-4.620694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-51.895660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.232056</td>\n",
       "      <td>-1.585591</td>\n",
       "      <td>-0.774071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.524385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024851</td>\n",
       "      <td>-0.029248</td>\n",
       "      <td>-0.031575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>14.932051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.275864</td>\n",
       "      <td>1.557381</td>\n",
       "      <td>0.754355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.022460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.124257</td>\n",
       "      <td>7.803660</td>\n",
       "      <td>4.177833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>76.885242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3       p            T  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.0  5000.000000   \n",
       "mean      0.026132    -0.024901    -0.015886     1.0     0.503000   \n",
       "std       1.876621     2.335915     1.140894     0.0     0.500041   \n",
       "min      -7.178571    -7.798972    -4.620694     1.0     0.000000   \n",
       "25%      -1.232056    -1.585591    -0.774071     1.0     0.000000   \n",
       "50%       0.024851    -0.029248    -0.031575     1.0     1.000000   \n",
       "75%       1.275864     1.557381     0.754355     1.0     1.000000   \n",
       "max       7.124257     7.803660     4.177833     1.0     1.000000   \n",
       "\n",
       "                cl            y  \n",
       "count  5000.000000  5000.000000  \n",
       "mean      5.500000    15.026427  \n",
       "std       2.872569    18.751313  \n",
       "min       1.000000   -51.895660  \n",
       "25%       3.000000     2.524385  \n",
       "50%       5.500000    14.932051  \n",
       "75%       8.000000    28.022460  \n",
       "max      10.000000    76.885242  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment parameters\n",
    "np.random.seed(123) #set seed\n",
    "nsize = 10000 #sample size\n",
    "\n",
    "# we create simulated data starting from a given variance-covariance matrix\n",
    "\n",
    "# variance-covariance matrix (simetric)\n",
    "cov = np.array([\n",
    "        [  3.40, -2.75, -2.00],\n",
    "        [ -2.75,  5.50,  1.50],\n",
    "        [ -2.00,  1.50,  1.25]\n",
    "    ])\n",
    "\n",
    "X = norm.rvs(size=(3, nsize)) #vector of variables N(0,1)\n",
    "evals, evecs = eigh(cov) #eigenvalues and eigenvector from var-covar matrix\n",
    "c = np.dot(evecs, np.diag(np.sqrt(evals))) #cholesky decomposition\n",
    "Xc = np.dot(c, X) #introduce correlation to matrix X\n",
    "Xc = Xc.transpose() \n",
    "Xc = pd.DataFrame(Xc, columns=['X1','X2','X3']) \n",
    "\n",
    "#time periods and treatment asignment \n",
    "Xc['p'] = 1\n",
    "Xc.loc[0:4999,'p'] = 0\n",
    "tr = np.random.binomial(1, 0.5, size=5000) #treatment status\n",
    "Xc.loc[0:4999,'T'] = tr\n",
    "Xc.loc[5000:9999,'T'] = tr \n",
    " \n",
    "#grouping variable\n",
    "Xc['cl']=1\n",
    "Xc.loc[500:999,'cl']=2\n",
    "Xc.loc[1000:1499,'cl']=3\n",
    "Xc.loc[1500:1999,'cl']=4\n",
    "Xc.loc[2000:2499,'cl']=5\n",
    "Xc.loc[2500:2999,'cl']=6\n",
    "Xc.loc[3000:3499,'cl']=7\n",
    "Xc.loc[3500:3999,'cl']=8\n",
    "Xc.loc[4000:4499,'cl']=9\n",
    "Xc.loc[4500:4999,'cl']=10\n",
    "Xc.loc[5500:5999,'cl']=2\n",
    "Xc.loc[6000:6499,'cl']=3\n",
    "Xc.loc[6500:6999,'cl']=4\n",
    "Xc.loc[7000:7499,'cl']=5\n",
    "Xc.loc[7500:7999,'cl']=6\n",
    "Xc.loc[8000:8499,'cl']=7\n",
    "Xc.loc[8500:8999,'cl']=8\n",
    "Xc.loc[9000:9499,'cl']=9\n",
    "Xc.loc[9500:9999,'cl']=10\n",
    "\n",
    "#outcome variable\n",
    "Xc['y'] = 10*(1+Xc['X1']) + 10*(Xc['X2']+Xc['T']*Xc['p']) + Xc['X3'] \n",
    "\n",
    "#data description\n",
    "Xc.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Controlled Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can estimate the sample size needed for a given effect (power analysis). In this example we estimate a sample size for a standarized effect of 0.2, a signficance of 95% (alpha=0.05), and power of 0.9 (chances of a false negative are 10%).\n",
    "\n",
    "Based on the formula, given an independent sample, we require 526 individuals, divided evenly between treatment and control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 526.000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# parameters for power analysis \n",
    "effect = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.9\n",
    "\n",
    "# perform power analysis \n",
    "analysis = TTestIndPower()\n",
    "result = analysis.solve_power(effect, power = power, nobs1= None, ratio = 1.0, alpha = alpha)\n",
    "print('Sample Size: %.3f' % round(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the data generated we can estimate the treatment effect (post-test only) using OLS and creating some additional variables as needed. We restrict to the data in the second period, when the treatment ocurrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.068\n",
      "Model:                            OLS   Adj. R-squared:                  0.067\n",
      "Method:                 Least Squares   F-statistic:                     362.2\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):           4.96e-78\n",
      "Time:                        13:31:57   Log-Likelihood:                -21576.\n",
      "No. Observations:                5000   AIC:                         4.316e+04\n",
      "Df Residuals:                    4998   BIC:                         4.317e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.1229      0.363     27.867      0.000       9.411      10.835\n",
      "T              9.7485      0.512     19.033      0.000       8.744      10.753\n",
      "==============================================================================\n",
      "Omnibus:                        0.156   Durbin-Watson:                   1.930\n",
      "Prob(Omnibus):                  0.925   Jarque-Bera (JB):                0.178\n",
      "Skew:                          -0.012   Prob(JB):                        0.915\n",
      "Kurtosis:                       2.982   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#post-test\n",
    "y = Xc.loc[5000:9999,'y']\n",
    "X = Xc.loc[5000:9999,'T']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate via OLS the treatment effect using differences in differences. We use all the data, and create a variable that represents the interaction between time and treatment status. By construction, treatment status and time variables alone have no impact on the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.055\n",
      "Model:                            OLS   Adj. R-squared:                  0.055\n",
      "Method:                 Least Squares   F-statistic:                     194.2\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):          2.02e-122\n",
      "Time:                        13:32:05   Log-Likelihood:                -43129.\n",
      "No. Observations:               10000   AIC:                         8.627e+04\n",
      "Df Residuals:                    9996   BIC:                         8.629e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.6617      0.362     26.657      0.000       8.951      10.372\n",
      "p              0.4613      0.513      0.900      0.368      -0.543       1.466\n",
      "T              0.0407      0.511      0.080      0.936      -0.961       1.042\n",
      "dd             9.7077      0.723     13.432      0.000       8.291      11.124\n",
      "==============================================================================\n",
      "Omnibus:                        0.643   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.725   Jarque-Bera (JB):                0.647\n",
      "Skew:                          -0.020   Prob(JB):                        0.724\n",
      "Kurtosis:                       2.996   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#pre-post test\n",
    "y=Xc['y']\n",
    "Xc['dd']= Xc['p']*Xc['T']\n",
    "X=Xc[['p','T','dd']]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results2 = model.fit()\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we estimate differences in differences but adjusting the standard errors based on the cluster variable. Since we did not create correlation within groups, the differences between both estimators are neglible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.055\n",
      "Model:                            OLS   Adj. R-squared:                  0.055\n",
      "Method:                 Least Squares   F-statistic:                     343.0\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):           1.36e-09\n",
      "Time:                        13:32:15   Log-Likelihood:                -43129.\n",
      "No. Observations:               10000   AIC:                         8.627e+04\n",
      "Df Residuals:                    9996   BIC:                         8.629e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.6617      0.379     25.484      0.000       8.919      10.405\n",
      "p              0.4613      0.341      1.353      0.176      -0.207       1.129\n",
      "T              0.0407      0.503      0.081      0.935      -0.946       1.027\n",
      "dd             9.7077      0.564     17.214      0.000       8.602      10.813\n",
      "==============================================================================\n",
      "Omnibus:                        0.643   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.725   Jarque-Bera (JB):                0.647\n",
      "Skew:                          -0.020   Prob(JB):                        0.724\n",
      "Kurtosis:                       2.996   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "#clustered standard errors\n",
    "results3 = model.fit(cov_type=\"cluster\", cov_kwds={'groups': Xc['cl']})\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **charls.csv** we will estimate basic difference estimator (treatment effect), intent to treat, and instrumental variables. The intervention is a public pension (*nrps*) and the outcome variable is retirement status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bnrps</th>\n",
       "      <th>cesd</th>\n",
       "      <th>child</th>\n",
       "      <th>dnrps</th>\n",
       "      <th>female</th>\n",
       "      <th>hrsusu</th>\n",
       "      <th>hsize</th>\n",
       "      <th>intmonth</th>\n",
       "      <th>married</th>\n",
       "      <th>nrps</th>\n",
       "      <th>retage</th>\n",
       "      <th>retired</th>\n",
       "      <th>schadj</th>\n",
       "      <th>urban</th>\n",
       "      <th>wave</th>\n",
       "      <th>wealth</th>\n",
       "      <th>inid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>2.104500e+04</td>\n",
       "      <td>21045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.386553</td>\n",
       "      <td>59.610683</td>\n",
       "      <td>8.656878</td>\n",
       "      <td>2.825232</td>\n",
       "      <td>0.740889</td>\n",
       "      <td>0.521026</td>\n",
       "      <td>2.548166</td>\n",
       "      <td>3.585222</td>\n",
       "      <td>7.511143</td>\n",
       "      <td>0.907674</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>1.280969</td>\n",
       "      <td>0.204942</td>\n",
       "      <td>4.162414</td>\n",
       "      <td>0.206652</td>\n",
       "      <td>1.909385</td>\n",
       "      <td>6.783959e+03</td>\n",
       "      <td>12747.082870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.016106</td>\n",
       "      <td>51.905928</td>\n",
       "      <td>6.307677</td>\n",
       "      <td>1.372179</td>\n",
       "      <td>0.438157</td>\n",
       "      <td>0.499570</td>\n",
       "      <td>1.757182</td>\n",
       "      <td>1.720136</td>\n",
       "      <td>0.865851</td>\n",
       "      <td>0.289492</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>3.830963</td>\n",
       "      <td>0.403669</td>\n",
       "      <td>3.540039</td>\n",
       "      <td>0.404914</td>\n",
       "      <td>0.817975</td>\n",
       "      <td>5.453065e+04</td>\n",
       "      <td>7769.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.648450e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>13314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>74.875404</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.800000e+03</td>\n",
       "      <td>19650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.040000e+06</td>\n",
       "      <td>25403.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age         bnrps          cesd         child         dnrps  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean      59.386553     59.610683      8.656878      2.825232      0.740889   \n",
       "std        9.016106     51.905928      6.307677      1.372179      0.438157   \n",
       "min       20.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       52.000000      0.000000      4.000000      2.000000      0.000000   \n",
       "50%       59.000000     60.000000      7.000000      3.000000      1.000000   \n",
       "75%       65.000000     74.875404     12.000000      4.000000      1.000000   \n",
       "max       95.000000    300.000000     30.000000     10.000000      1.000000   \n",
       "\n",
       "             female        hrsusu         hsize      intmonth       married  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean       0.521026      2.548166      3.585222      7.511143      0.907674   \n",
       "std        0.499570      1.757182      1.720136      0.865851      0.289492   \n",
       "min        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "25%        0.000000      0.000000      2.000000      7.000000      1.000000   \n",
       "50%        1.000000      3.401197      3.000000      7.000000      1.000000   \n",
       "75%        1.000000      4.025352      5.000000      8.000000      1.000000   \n",
       "max        1.000000      5.123964     16.000000     12.000000      1.000000   \n",
       "\n",
       "               nrps        retage       retired        schadj         urban  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean       0.519078      1.280969      0.204942      4.162414      0.206652   \n",
       "std        0.499648      3.830963      0.403669      3.540039      0.404914   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      4.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      8.000000      0.000000   \n",
       "max        1.000000     51.000000      1.000000     16.000000      1.000000   \n",
       "\n",
       "               wave        wealth          inid  \n",
       "count  21045.000000  2.104500e+04  21045.000000  \n",
       "mean       1.909385  6.783959e+03  12747.082870  \n",
       "std        0.817975  5.453065e+04   7769.025809  \n",
       "min        1.000000 -1.648450e+06      1.000000  \n",
       "25%        1.000000  1.000000e+02   5176.000000  \n",
       "50%        2.000000  1.000000e+03  13314.000000  \n",
       "75%        3.000000  6.800000e+03  19650.000000  \n",
       "max        3.000000  1.040000e+06  25403.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charls = pd.read_csv('../data/charls.csv')\n",
    "charls.dropna(inplace=True)\n",
    "charls.reset_index(drop=True, inplace=True)\n",
    "\n",
    "charls.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ignore the panel nature of the data and estimate the overall effect of pension status on retirement status using a linear probability model. We incoporate control variables that could predict treatment status. \n",
    "\n",
    "Taken all together, pension access reduces the probability to retire by 2.6 percent points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.124\n",
      "Model:                            OLS   Adj. R-squared:                  0.124\n",
      "Method:                 Least Squares   F-statistic:                     530.8\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:47:06   Log-Likelihood:                -9376.5\n",
      "No. Observations:               21045   AIC:                         1.876e+04\n",
      "Df Residuals:                   21039   BIC:                         1.881e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6142      0.025    -24.987      0.000      -0.662      -0.566\n",
      "married       -0.0745      0.011     -6.718      0.000      -0.096      -0.053\n",
      "female         0.1045      0.005     20.137      0.000       0.094       0.115\n",
      "age            0.0143      0.000     43.726      0.000       0.014       0.015\n",
      "hsize         -0.0002      0.002     -0.151      0.880      -0.003       0.003\n",
      "nrps          -0.0260      0.005     -4.971      0.000      -0.036      -0.016\n",
      "==============================================================================\n",
      "Omnibus:                     3404.726   Durbin-Watson:                   1.451\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5359.254\n",
      "Skew:                           1.230   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.254   Cond. No.                         559.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','nrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "\n",
    "model = sm.OLS(ya, Xa)\n",
    "results = model.fit(cov_type=\"HC1\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumental Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate the intent-to-treat using the variable that reflects whether the pension is offered or not (dnrps). As noted in the descriptive statistics, the pension is offered to 3/4 of the population, and roughly 2/3 of those are enrolled.\n",
    "\n",
    "As noted, the intent-to-treat (being offered the pension) is not significant to the retiremnt decision. For instrumental variables, this is known as the exclusion restriction (instrument affects treatment status but not outcome). Therefore, *dnrps* is a good candidate as an instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                     526.5\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:47:18   Log-Likelihood:                -9388.0\n",
      "No. Observations:               21045   AIC:                         1.879e+04\n",
      "Df Residuals:                   21039   BIC:                         1.884e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6246      0.025    -25.270      0.000      -0.673      -0.576\n",
      "married       -0.0780      0.011     -7.032      0.000      -0.100      -0.056\n",
      "female         0.1035      0.005     19.937      0.000       0.093       0.114\n",
      "age            0.0142      0.000     43.332      0.000       0.014       0.015\n",
      "hsize      -7.731e-06      0.002     -0.005      0.996      -0.003       0.003\n",
      "dnrps          0.0077      0.006      1.309      0.191      -0.004       0.019\n",
      "==============================================================================\n",
      "Omnibus:                     3413.088   Durbin-Watson:                   1.446\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5378.645\n",
      "Skew:                           1.232   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.252   Cond. No.                         561.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','dnrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "\n",
    "model = sm.OLS(ya, Xa)\n",
    "results = model.fit(cov_type=\"HC1\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we re-estimate the natural experiment design but using instrumental variables, so we explore the LATE effect, instead of ATE effect. The instrument is implementation date of the policy (*dnrps*).\n",
    "\n",
    "We estimate the first stage, then predict the expected values, and use those (pnrps) instead of actual treatment status (nrps) in the second stage. \n",
    "\n",
    "As expected, the instrument has a significant impact on treatment status. However, results from the second stage indicate that there is no longer a relationship between the pension and retirement status. The Wald estimator for the LATE indicates a positive relationship but not significant.\n",
    "\n",
    "In summary, the ATE effect is negative, however it could be biased because omitted variables that are determining whether individuals access to the pension and retire simulaneously. Once we use an instrument to control for endogeneity, there is no longer a relationship between the pension and retirement in this sample.\n",
    "\n",
    "For additional info see:\n",
    "\n",
    "Parada-Contzen and Caro (2022) Pension Incentives and Retirement Planning in Rural China: Evidence for the New Rural Pension Scheme. https://doi.org/10.1111/deve.12297  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   nrps   R-squared:                       0.378\n",
      "Model:                            OLS   Adj. R-squared:                  0.378\n",
      "Method:                 Least Squares   F-statistic:                     9150.\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:53:41   Log-Likelihood:                -10257.\n",
      "No. Observations:               21045   AIC:                         2.052e+04\n",
      "Df Residuals:                   21040   BIC:                         2.056e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0101      0.023     -0.430      0.667      -0.056       0.036\n",
      "married       -0.0116      0.009     -1.259      0.208      -0.030       0.006\n",
      "female         0.0283      0.005      5.152      0.000       0.018       0.039\n",
      "age         9.153e-05      0.000      0.281      0.779      -0.001       0.001\n",
      "dnrps          0.7012      0.004    188.106      0.000       0.694       0.709\n",
      "==============================================================================\n",
      "Omnibus:                     3275.813   Durbin-Watson:                   1.611\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3947.306\n",
      "Skew:                          -1.016   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.387   Cond. No.                         537.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xf=charls[['married','female','age','dnrps']]\n",
    "yf=charls['nrps']\n",
    "Xf = sm.add_constant(Xf)\n",
    "model = sm.OLS(yf, Xf)\n",
    "first = model.fit(cov_type=\"HC1\")\n",
    "charls['pnrps']=first.predict(Xf)\n",
    "\n",
    "print(first.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                     526.5\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:53:46   Log-Likelihood:                -9388.0\n",
      "No. Observations:               21045   AIC:                         1.879e+04\n",
      "Df Residuals:                   21039   BIC:                         1.884e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6245      0.025    -25.274      0.000      -0.673      -0.576\n",
      "married       -0.0779      0.011     -7.025      0.000      -0.100      -0.056\n",
      "female         0.1032      0.005     19.870      0.000       0.093       0.113\n",
      "age            0.0142      0.000     43.321      0.000       0.014       0.015\n",
      "hsize      -7.731e-06      0.002     -0.005      0.996      -0.003       0.003\n",
      "pnrps          0.0110      0.008      1.309      0.191      -0.005       0.027\n",
      "==============================================================================\n",
      "Omnibus:                     3413.088   Durbin-Watson:                   1.446\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5378.645\n",
      "Skew:                           1.232   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.252   Cond. No.                         561.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','pnrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "model = sm.OLS(ya, Xa)\n",
    "second = model.fit(cov_type=\"HC1\")\n",
    "\n",
    "print(second.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015658522589718157"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second.params['pnrps']/first.params['dnrps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "## Event study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the simulated data from the first section, we will explore the estimator for event study design. We create a dataset with 10 periods (determined by the time trend *cl*). In this setup, the variable y is a function of variables X1, X2 and time trend. Also, there is a treatment effect that increases only in the last two periods, when the intervention is active. To do this, we create a variable named Tc which reflects the additional effect due to treatment, interacted with the time period.\n",
    "\n",
    "By construction, there is a time effect, that increases after treatment, which is identified in the coefficient for the *Tc* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>T</th>\n",
       "      <th>cl</th>\n",
       "      <th>y</th>\n",
       "      <th>Tc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026132</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>25.201627</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876621</td>\n",
       "      <td>2.335915</td>\n",
       "      <td>0.40004</td>\n",
       "      <td>2.872569</td>\n",
       "      <td>18.412630</td>\n",
       "      <td>3.806954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.178571</td>\n",
       "      <td>-7.798972</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-23.692425</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.232056</td>\n",
       "      <td>-1.585591</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.262571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024851</td>\n",
       "      <td>-0.029248</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>22.595764</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.275864</td>\n",
       "      <td>1.557381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>35.658769</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.124257</td>\n",
       "      <td>7.803660</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>91.085033</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           T           cl            y  \\\n",
       "count  5000.000000  5000.000000  5000.00000  5000.000000  5000.000000   \n",
       "mean      0.026132    -0.024901     0.20000     5.500000    25.201627   \n",
       "std       1.876621     2.335915     0.40004     2.872569    18.412630   \n",
       "min      -7.178571    -7.798972     0.00000     1.000000   -23.692425   \n",
       "25%      -1.232056    -1.585591     0.00000     3.000000    12.262571   \n",
       "50%       0.024851    -0.029248     0.00000     5.500000    22.595764   \n",
       "75%       1.275864     1.557381     0.00000     8.000000    35.658769   \n",
       "max       7.124257     7.803660     1.00000    10.000000    91.085033   \n",
       "\n",
       "                Tc  \n",
       "count  5000.000000  \n",
       "mean      1.900000  \n",
       "std       3.806954  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max      10.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe = Xc.loc[5000:9999]\n",
    "Xe = Xe[['X1','X2','T','cl','y']]\n",
    "Xe.reset_index(drop=True, inplace=True)\n",
    "Xe.loc[0:3999,'T'] = 0\n",
    "Xe.loc[4000:4999,'T'] = 1\n",
    "Xe['Tc']= Xe['cl']*Xe['T']\n",
    "Xe['y'] = 5+5*Xe['X2'] + 2*Xe['Tc'] + 3*Xe['cl'] + Xe['X1'] \n",
    "\n",
    "Xe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.670\n",
      "Model:                            OLS   Adj. R-squared:                  0.670\n",
      "Method:                 Least Squares   F-statistic:                     4983.\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        14:15:57   Log-Likelihood:                -18886.\n",
      "No. Observations:                5000   AIC:                         3.778e+04\n",
      "Df Residuals:                    4997   BIC:                         3.780e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.2795      0.373     14.156      0.000       4.549       6.010\n",
      "Tc             2.1124      0.055     38.518      0.000       2.005       2.220\n",
      "cl             2.8925      0.073     39.598      0.000       2.749       3.036\n",
      "==============================================================================\n",
      "Omnibus:                        0.350   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.839   Jarque-Bera (JB):                0.392\n",
      "Skew:                          -0.011   Prob(JB):                        0.822\n",
      "Kurtosis:                       2.963   Cond. No.                         17.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "ye = Xe['y']\n",
    "Xe = Xe[['Tc','cl']]\n",
    "Xe = sm.add_constant(Xe)\n",
    "model = sm.OLS(ye, Xe)\n",
    "results = model.fit(cov_type=\"HC1\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Tarea 3**</font>\n",
    "\n",
    "<u> *Instrucciones* </u>\n",
    "\n",
    "Los resultados de los ejericicios propuestos se deben entregar como un notebook por correo electronico a *juan.caro@uni.lu* el dia 25/11 hasta las 21:00. \n",
    "\n",
    "Es importante considerar que el cdigo debe poder ejecutarse en cualquier computadora con la data original del repositorio. Recordar la convencion para el nombre de archivo ademas de incluir en su documento titulos y encabezados por seccion. La unica data real a utilizar en parte de esta tarea es **charls.csv**. El resto de la data de la tarea debe ser generada a partir de las caracteristicas que se especifican. Las variables en **charls.csv** tienen la siguiente descripcion:\n",
    "\n",
    "- inid: identificador unico\n",
    "- wave: periodo de la encuesta (1-3)\n",
    "- cesd: puntaje en la escala de salud mental (0-30)\n",
    "- child: numero de hijos\n",
    "- drinkly: bebio alcohol en el ultimo mes (binario)\n",
    "- hrsusu: horas promedio trabajo semanal\n",
    "- hsize: tamano del hogar\n",
    "- intmonth: mes en que fue encuestado/a (1-12)\n",
    "- married: si esta casado/a (binario)\n",
    "- retired: si esta pensionado/a (binario)\n",
    "- schadj: aos de escolaridad\n",
    "- urban: zona urbana (binario)\n",
    "- wealth: riqueza neta (miles RMB)\n",
    "- age: edad al entrar a la encuesta (no varia entre periodos)\n",
    "- bnrps: monto de pension publica (en RMB/mes)\n",
    "- dnrps: pension implementada en la provincia (binaria)\n",
    "- retage: fecha esperada de retiro (aos desde la fecha de encuenta)\n",
    "- female: genero del encuestado\n",
    "- nrps: recibe pension publica\n",
    "\n",
    "Preguntas:\n",
    "\n",
    "Parte 1 - Experimentos\n",
    "\n",
    "Deben conceptualizar un experimento con el objetivo de estudiar posibles incentivos o estrategias para incrementar la asistencia a clases en estudiantes universitarios de la UdeC. El outcome del tratamiento es la proporcion promedio de estudiantes que asisten a clases. Todos los elementos del experimento deben ser definidos, respondiendo a las siguientes preguntas: \n",
    "\n",
    "1. Asumiendo la existencia de recursos disponibles e implementacion a nivel de estudiante, sugiera un tratamiento que pueda ser testeado a traves de un experimento aleatorizado controlado. Sea especifico en cuanto a los detalles del tratamiento (costos, materiales, duracion, etcetera).\n",
    "\n",
    "**R:** La definicion especifica de la intervencion debe ser tal que 1) permita un mecanismo de asignacion aleatoria, 2) el tratamiento pueda aplicarse de forma invidiual (no a nivel de curso), y 3) minimize cualquier posibilidad de contaminacion entre grupos o atricion selectiva.\n",
    "\n",
    "Mientras mas se restrinja la poblacion donde se aplicara la intervencion, mas afectara su validez externa (por ejemplo si se restringe solo a ciertos cursos o periodos de ingreso).\n",
    "\n",
    "2. Defina los grupos de tratamiento y control para implementar su experimento. Describa en detalle el mecanismo de asignacion aleatorio que permite la comparacion entre grupos.\n",
    "\n",
    "**R:** El mecanismo de asignacion debe permitir que los grupos sean comparables, por lo tanto debe ser aleatorio de tal forma que no exista posibilidad de manipulacion por parte de los estudiantes o el investigador. Utilizar los ID unicos de los estudiantes y un metodo privado de entrega permite minimizar problemas tanto con la asignacion como con la entrega del tratamiento.\n",
    "\n",
    "3. Que metodo considera el mas apropiado para la estimacion del efecto promedio? (pre-test, pre-post test, Salomon 4 group). Justifique su respuesta en base a las ventajas y desventajas de cada metodo. \n",
    "\n",
    "**R:** Se espera que exista una tendencia en la asistencia en el tiempo, por tanto un modelo post-test es menos adecuado. Si se espera que ademas existan diferencias que puedan darse por la introduccion de un pre-test, el diseno Salomon seria adecuado, sin embargo dado que es comun tener asistencia en clases, no se espera que sea necesario agregar recursos para hacer una comparacion solo post en una submuestra.\n",
    "\n",
    "4. Ahora suponga que no es posible implementar un experimento a nivel de estudiante, sino a nivel de clase. Como ajustaria los elementos de su experimento para poder ser implementado a nivel de cluster? Sea especifico respecto tanto del tratamiento como del metodo de asignacion aleatorio y potencial comparacion entre grupos de tratamiento y control.\n",
    "\n",
    "**R:** Trabajar a nivel de curso implica en general: 1) aumentar el tamano de muestra, dado que la correlacion dentro de cada grupo requiere un mayor numero de observaciones para estimar el efecto del tratamiento, y 2) corregir los errores estandar por la correlacion dentro del grupo. En cuanto al mecanismo de asignacion, los cursos deben ser elegidos aleatoriamente y dentro de cada curso (grupo), todos los estudiantes son sujeto de tratamiento.\n",
    "\n",
    "5. Suponga que en vez de un experimento, se planifica que sea un programa implementado a nivel de toda la Universidad. Como ajustaria los elementos descritos anteriormente para poder comparar el efecto de la intervencion.  \n",
    "\n",
    "**R:** Este diseno es lo que se cosnidera como estudio de eventos, y se podria utilizar data historica, si esta disponible, para estimar la tendencia esperada que ocurriria si la Universidad no implementara la politica. Es importante considerar cualquier evento que pueda afectar la tendencia, tanto estacional (feriados) como aleatorio (e.g. COVID).\n",
    "\n",
    "Parte 2 - Estimacion de efectos promedio de tratamiento (data simulada)\n",
    "\n",
    "6. A partir de sus respuestas en Parte 1, genere data para 40 grupos (considere cada grupo como una clase) con 50 estudiantes cada uno (asuma que los estudiantes son asignados aleatoriamente a cada clase). Cada estudiante debe tener data de asistencia en un periodo, generando una variable binaria aleatoria talque la asistencia promedio a traves de todos los grupos es de 80%.\n",
    "\n",
    "**R:** Tal como se discutio en clases, es una base de 4,000 observaciones, donde 1,000 individuos se asignan a tratamiento y 1,000 se asignan a control (los 2,000 alumnos estan aleatoreamente distribuidos entre 40 clases de tamano 50). El analisis de poder sugiere que basta con aproximadamente 1,500 alumnos para poder identificar el efecto estimado. La variable de resultado (y) debe ser aletoria en el primer periodo y binaria (0/1).\n",
    "\n",
    "7. Genere un mecanismo de asignacion aleatorio a nivel de estudiante y muestre que en la data generada permite que ambos grupos (tratamiento y control) tienen una asistencia promedio comparable.\n",
    "\n",
    "**R:** El mecanismo de asignacion debe ser tal que el individuo tratado (o control) mantiene su estado en cada periodo (recordando que ademas debe mantenerse en la misma clase). \n",
    "\n",
    "8. Genere un tratamiento que imcrementa la participacion en el grupo de tratamiento en 10 puntos porcentuales. Ademas en la data posterior al experimento, asuma que la participacion promedio cayo a 75%. Estime el efecto promedio del tratamiento usando solo post-test.\n",
    "\n",
    "**R:** Tal como se discutio en clases, el efecto del tratamiento es 15 puntos porcentuales, ya que en el grupo control cae en 5 puntos y aumenta en el tratamiento en 10 puntos. El resultado del post-test aplicado a la variable binaria usando probabilidad lineal (OLS) o modelo binario (Probit, Logit) deberia generar este resultado.\n",
    "\n",
    "9. Estime el efecto promedio del tratamiento usando pre-post test con la data generada. Muestre que el efecto es equivalente usando ambos metodos.\n",
    "\n",
    "**R:** Al incorporar el indicador de tratamiento y tendencia en el pre-post, deberia ser 0 en el tratamiento (grupos balanceados), coeficiente de tendencia -0.05 y coeficiente de tratamiento 0.15.\n",
    "\n",
    "10. Estime el efecto ajustando los errores estandar por cluster (la variable grupo representa cada clase). Cual es la diferencia entre ambas estimaciones? Explique porque es esperable (o no) encontrar diferencias entre ambos metodos.\n",
    "\n",
    "**R:** Idem anterior, diferencias marginales dado que la asignacion de cada estudiante a cada grupo es aleatoria (no hay correlacion dentro del grupo). Basta usar cualquier estimador robusto de varianza-covarianza.\n",
    "\n",
    "Parte 3 - Experimentos naturales \n",
    "\n",
    "Usando la data **charls.csv**, responda las siguientes preguntas relativas a experimentos naturales.\n",
    "\n",
    "11. Simule un experimento natural (e.g. intervencion de politica publica) tal que se reduce la proporcion de individuos con 3 hijos o mas que declaran beber alcohol en el tercer periodo a la mitad. Para ello, genere una variable de tratamiento (todos los individuos con mas de 2 hijos son parte de la intervencion), y una nueva variable llamada *sdrinlky*, talque es identica a *drinkly* en los periodos 1 y 2 , pero sustituya los valores aleatoriamente en el periodo 3 para generar el efecto esperado.\n",
    "\n",
    "**R:** Tal como en la seccion anterior, la nueva variable de resultado *sdrinkly* es identica a *drinkly* salvo que en el tercer periodo, la mitad de los individuos con 3 hijos o mas (aleatoriamente) reportan un valor de 0 en vez de su valor original (1).\n",
    "\n",
    "12. Estime el efecto del tratamiento usando diferencias en diferencias, comparando entre los periodos 2 y 3. \n",
    "\n",
    "**R:** Por construccion, el efecto del tratamiento tiene que ser exactamente la mitad de caida en la prevalencia. Si hay algun efecto de tendencia, la diferencia en el control puede ser distinta de cero, mientras que se espera alguna diferencia entre los grupos de control y tratamiento, dado que la seleccion no es aleatoria.\n",
    "\n",
    "13. Compare el efecto del tratamiento generando grupos pseudo-equivalentes, en particular entre individuos solo con 3 hijos (tratamiento) y 2 hijos (control). \n",
    "\n",
    "**R:** Idem a la pregunta anterior, restringiendo la muestra. El efecto en los tratados se mantiene igual, mientras que deberia variar tanto algun potencial efecto de tendencia como de asignacion de grupos (es esperable que exista menor diferencia entre el grupo de control y tratamiento en el primer periodo).\n",
    "\n",
    "14. Estime el efecto anterior usando la variable *married* como instrumento para determinar el efecto del tratamiento en la pregunta 12. Como se interpreta el efecto en este caso?\n",
    "\n",
    "**R:** En este caso primero deben hacer una regression usando distintas variables base ademas de married para predecir sdrkinly en la sub-muestra de la pregunta 13, luego usar esa variable predicha (denotemos como p_sdrinkly) para estimar el efecto de tratamiento. El efecto deberia ser diferente al anterior dado que es un estimador de variables instrumentales. En su tarea deben mostrar tanto la primera como la segunda etapa.\n",
    "\n",
    "15. Finalmente, asuma que la intervencion se implementa en todos los individuos. Genere una nueva variable de tratamiento un nueva variable llamada *tdrinkly* donde el efecto es una reduccion de 50% en la prevalencia de consumo de alcohol en toda la poblacion en el tercer periodo (identica a *drinkly* en los periodos 1 y 2). Genere una variable *cdrinkly* que es identica a *drinkly* en los periodos 1 y 2 y use la informacion de ambos periodos para predicir el valor esperado de *drinkly* en el tercer periodo, estos seran los valores de *cdrinkly* en el periodo 3 (contrafactual). Finalmente, estime el efecto de la intervencion en toda la poblacion comparando entre *tdrinkly* (datos reales) versus *cdrinkly* contrafactual.   \n",
    "\n",
    "**R:** En este caso deben primero estimar el efecto de las distintas variables en *drinkly* usando la data de los primeros dos periodos mas una variable binaria de tiempo. Luego usando la data del tercer periodo pueden calcular *cdrinkly*, es decir el contrafactual que ocurriria sin intervencion. Luego el efecto de la intervencion corresponde a comparar el valor del tratamiento (*tdrinlky*, donde hay una reduccion del 50%) contra el contrafactual. Notar que *cdrinkly* puede ser distinta a *drinkly* dado que es una prediccion (en este ejercicio el valor observado en la realidad es *tdrinkly*, dado que la intervencion ocurrio en el periodo 3)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
